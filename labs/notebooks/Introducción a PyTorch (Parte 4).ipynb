{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a PyTorch (Parte 4)\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/pglez82/DeepLearningWeb/blob/master/labs/notebooks/Introducci%C3%B3n%20a%20PyTorch%20(Parte%204).ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "### Datasets y Dataloaders\n",
    "\n",
    "Las clases `torch.utils.data.DataSet` y `torch.utils.data.DataLoader` son las clases básicas que usamos en PyTorch para la carga eficiente de datos. Manejarlas bien por tanto es crítico para llevar a cabo el entrenamiento de una red profunda con éxito. Estas dos clases tienen objetivos diferentes:\n",
    "- La clase `DataSet` abstrae el concepto de conjunto de datos, almacenando los ejemplos y su etiqueta correspondiente y proveyendo métodos para la obtención de uno de estos ejemplos.\n",
    "- La clase `DataLoader` encapsula a un `DataSet` y permite el acceso eficiente a lotes de ejemplos.\n",
    "\n",
    "Es importante destacar que estas clases permiten el acceso a datasets ya creados como por ejemplo MNIST o ImageNet, así como a datasets con nuestros datos. Ten en cuenta que no solo serán datasets con imágenes sino que tendremos diferentes subclases para otros tipos de datasets.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de un DataSet\n",
    "En este caso vamos a cargar el conocido dataset MNIST. Este dataset tiene 60.000 ejemplos de entrenamiento y 10.000 ejemplos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.MNIST(root=\"data\",train=True,download=True,transform=ToTensor())\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "print(\"Datos de entrenamiento:\")\n",
    "print(training_data, end='\\n\\n')\n",
    "print(\"Datos de test:\")\n",
    "print(test_data, end='\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Los parámetros usados son los siguientes:\n",
    "- **root**. ruta donde se almacenará el dataset en nuestro dispositivo de almacenamiento.\n",
    "- **train**. Especifica si queremos el conjunto de entrenamiento o el de test.\n",
    "- **download**. Si le pasamos true, descarga los datos de internet si no están disponibles en el directorio root.\n",
    "- **transform**. Transforma los ejemplos antes de devolverlos. Es útil para hacer **aumento de datos** que veremos en otra práctica. En este caso lo usamos para convertir las imágenes a un tensor que nos sirva para nuestra red neuronal.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando el dataset\n",
    "Vamos ahora a visualizar algunas imágenes aleatoriamente. Ten en cuenta que para realizar esto, podemos acceder a cada elemento del dataset como si fuese un simple array o una lista `training_data[i]`. Este código devuelve el ejemplo i-ésimo así como la etiqueta del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividiendo el DataSet\n",
    "Es común que queramos dividir el dataset de entrenamiento para separar una parte para **validación**. PyTorch tiene una función muy útil para ello que permite hacerlo rápidamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(training_data, (50000, 10000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetivos devueltos por **random_split** son de tipo `Subset`. A efectos prácticos, esta clase funciona igual que DataSet y es capaz de devolvernos ejemplos individuales directamente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otros tipos de DataSets (TensorDataSet)\n",
    "Supongamos ahora que nuestros datos no son imágenes. Imaginemos que tenemos datos de tipo tabular. En este caso la clase que hay que utilizar es `TensorDataSet` (que extiende de `DataSet`). Esta clase recibe en su constructor un número de tensores (típicamente dos, uno para las `X` y otro para las `y`). Veamos su uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "#Generar datos para nuestro dataset.\n",
    "X = torch.rand((100,2))\n",
    "y = torch.randint(low=0,high=2,size=(100,))\n",
    "\n",
    "custom_training_data = TensorDataset(X,y)\n",
    "print(\"Imprimiento el primer ejemplo de nuestro dataset bidimensional:\")\n",
    "print(custom_training_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando nuestra propia subclase de DataSet\n",
    "Existen circunstancias en las que es adecuado crear nuestra subclase de la clase `DataSet`. Por ejemplo, esto ocurre cuando queremos cargar imágenes de un directorio. Un ejemplo de este uso sería el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = torch.tensor(self.img_labels.iloc[idx, 1])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para extender a DataSet siempre tendremos que implementar:\n",
    "- El **constructor**, donde podemos pasarle todos los atributos que necesitemos.\n",
    "- El método `__len__`, que devuelve el tamaño del dataset.\n",
    "- El método `__getitem__`, que devuelve el elemento i-ésimo del dataset.\n",
    "\n",
    "Una alternativa a la clase anterior, si se necesita cargar **imágenes que están distribuidas en clases por directorios** es utilizar la clase \n",
    "`torchvision.datasets.ImageFolder`. La etiqueta de cada ejemplo se inferirá directamente de nombre del directorio correspondiente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La clase DataLoader\n",
    "Como has visto hasta ahora, un DataSet es capaz de devolver un ejemplo de cada vez. Típicamente cuando entrenamos una red neuronal profunda queremos pasarle a la red **mini-batches** de ejemplos. Además, necesitamos que la carga sea rápida para que el acceso a los datos no sea un cuello de botella en nuestro pipeline de entrenamiento. Aquí es donde la clase `DataLoader` es útil. Provee la funcionalidad necesaria para acceder a batches de ejemplos así como hacerlo en paralelo utilizando las capacidades de multiproceso de nuestra máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Dimensiones del batch (X): {train_features.size()}\")\n",
    "print(f\"Dimensiones del batch (y): {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver en el ejemplo anterior, estamos cargando 64 imágenes al mismo tiempo y el DataLoader nos devuelve dos tensores. El primero tiene un tamaño de **64x1x28x28**, que corresponde a 64 imagenes con un solo canal y unas dimensiones de 28x28 pixeles. Las etiquetas vendrán en un tensor unidimensional con un tamaño de 64. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orden de carga de los ejemplos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver en el ejemplo anterior, los ejemplos se cargan secuencialmente. Con el atributo **shuffle** controlamos si queremos que los ejemplos se desordenen antes de ser devueltos. Pero, gracias al DataLoader, podemos controlar de manera más fina el orden de los ejemplos. Para ello necesitamos usar el parámetro **sampler** y **batch_sampler** del DataLoader."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios propuestos\n",
    "1. Modifica la clase CustomImageDataset para que no haga falta pasarle las etiquetas de los ejemplos y las coja del subdirectorio en el que se encuentre la imagen. Puedes probar tu Dataset con el conjunto de datos [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/). Para ello descarga el archivo images.tar y verás que las imágenes de cada categoría se encuentran en un subdirectorio independiente. Para resolver el ejercicio no necesitas el archivo de anotaciones.\n",
    "2. Crea un batch sampler personalizado para que en cada batch los números vayan ordenados de menor a mayor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
