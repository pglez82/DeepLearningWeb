{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD11kuoOXGuR"
      },
      "source": [
        "# 4.4 - Redes convolucionales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer-learning y fine-tunning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A menudo, en lugar de diseñar y entrenar una CNN desde cero para abordar un problema específico, se utiliza una red pre-entrenada en un conjunto de datos amplio y variado.\n",
        "\n",
        "Esta técnica se conoce como **transfer-learning**. La idea principal es reutilizar los pesos y arquitectura de una red ya entrenada que ha aprendido características útiles y generales de las imágenes, y adaptarla a una nueva tarea específica. \n",
        "\n",
        "Para adaptar una red existente a nuestro problema, lo que haremos será eliminar las capas finales y utilizar solamente la *parte convolucional* o la parte de *extracción de características* (feature extraction en la siguiente figura):\n",
        "\n",
        "![image.png](https://i.imgur.com/vsSJBcu.png)\n",
        "\n",
        "A esta parte convolucional tendremos que añadir las capas necesarias para adaptar la salida del modelo al problema a resolver. Los pesos de la parte de extracción de características se congelan para que no se modifiquen y solo se entrena la parte final recién añadida.\n",
        "\n",
        "Otra alternativa es realizar lo que se denomina **transfer-learning + fine-tunning**. En este caso haremos exactamente lo mismo que en la parte de transfer-learning, pero los pesos de la parte convolucional del modelo pre-entrenado **no se congelan**, también se ajustan durante el entrenamiento con el conjunto de datos del nuevo problema. \n",
        "\n",
        "Hay que tener en cuenta que no nos interesa mover en gran medida estos pesos, solo ajustarlos, por tanto, en este escenario de *transfer-learning + fine-tunning* el learning-rate suele fijarse en un valor más bajo de lo habitual.\n",
        "\n",
        "A continuación verás un ejemplo de un modelo creado mediante transfer-learning. Para buscar modelos pre-entrenados para clasificación de imágenes puedes entrar [aquí](https://pytorch.org/vision/stable/models.html#classification)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Descargar y explorar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cargamos un modelo ResNet18 pre-entrenado para resolver el problema ImageNet y exploramos su arquitectura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "\n",
        "pretrained_model = models.resnet18(pretrained=True)\n",
        "print(pretrained_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como se puede ver, está compuesta de varias capas individuales y sub-modelos con nombre layer1, layer2, ...\n",
        "\n",
        "Vamos a explorar los nombres de los módulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, children in pretrained_model.named_children():\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La última capa (donde se resuelve el problema de clasificación ImageNet) se denomina ``fc``, vamos a ver que contiene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(pretrained_model.fc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nuestro objetivo será, por tanto, reemplazar esta capa por una que sirva para nuestro problema, lo que resultaría en el siguiente modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TransferLearningCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransferLearningCNN, self).__init__()\n",
        "        \n",
        "        # Cargar el modelo deseado\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "    \n",
        "        # Congelar todos los pesos del modelo pre-entrenado\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "        # Cambiamos la última capa del modelo (capa Fully connected (fc)) por una que se adapta a nuestro problema\n",
        "        self.model.fc = nn.Linear(512, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **EJERCICIO:** Crea un modelo para resolver el problema de CIFAR10 utilizando como base [Mobilenet_v3_small](https://pytorch.org/vision/stable/models/generated/torchvision.models.mobilenet_v3_small.html#torchvision.models.mobilenet_v3_small).\n",
        "\n",
        "> Compara una versión en la que solo realices transfer-learning con otra donde apliques transfer-learning y fine-tunning. \n",
        "\n",
        "> Utiliza solamente los 3 primeros bloques de capas del extractor de características.\n",
        "\n",
        "> Evalúa su rendimiento mostrando las imágenes y predicciones para el primer batch de test.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
