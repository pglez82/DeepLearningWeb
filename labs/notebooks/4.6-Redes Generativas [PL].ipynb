{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD11kuoOXGuR"
      },
      "source": [
        "# 4.6 - Redes Generativas Adversarias (GAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Además de los Autoencoders, otra de las arquitecturas más reconocidas para resolver problemas de aprendizaje no supervisado son las **Redes Generativas Adversarias (GAN)**.\n",
        "\n",
        "Las GANs fueron introducidas por Ian Goodfellow en 2014 y consisten en dos modelos que se entrenan simultáneamente: un **generador** y un **discriminador**. \n",
        "\n",
        "- El **generador** intenta crear datos falsos que sean indistinguibles de los datos reales a partir de, típicamente, un vector de ruido Gaussiano.\n",
        "- El **discriminador** intenta distinguir entre datos reales y falsos resolviendo un problema de clasificación binaria.\n",
        "\n",
        "El proceso de entrenamiento se denomina *\"adversario\"* puesto que el generador intenta engañar al discriminador, y el discriminador trata de no ser engañado.\n",
        "\n",
        "El objetivo del generador es maximizar la probabilidad de que el discriminador clasifique sus muestras generadas como reales. \n",
        "\n",
        "Por otro lado, el objetivo del discriminador es minimizar su tasa de error en la clasificación de las muestras reales y generadas.\n",
        "\n",
        "<br>\n",
        "\n",
        "En esta práctica crearemos una **Deep Convolutional Generative Adversarial Network (DCGAN)** para generar nuevas imágenes de dígitos del conjunto *MNIST*.\n",
        "\n",
        "Ten en cuenta que, aunque sea su uso más común, no todas las GAN tienen por que ser convolucionales o generar imágenes, también pueden generar datos estructurados o tabulares."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.6.1 - Conjunto de datos\n",
        "\n",
        "Utilizaremos de nuevo el conjunto [MNIST](https://es.wikipedia.org/wiki/Base_de_datos_MNIST). Como recordarás, este conjunto posee imágenes en escala de grises con números del 0 al 9 escritos a mano por personas. Cada una de estas imágenes tiene una resolución de $28 \\times 28$ píxels. Al ser en escala de grises, cada imagen será un tensor de $1 \\times 28 \\times 28$.\n",
        "\n",
        "Este conjunto de datos está pensado para resolver un problema de *Aprendizaje supervisado de multiclasificación*, pero en este caso descartaremos las etiquetas y utilizaremos solamente las imágenes.\n",
        "\n",
        "Para acelerar y simplificar el entrenamiento de la **DCGAN**, que puede ser temporalmente costoso, vamos a quedarnos solamente con imágenes de la clase 6.\n",
        "\n",
        "De esta forma, nuestra red solo tendrá que aprender a generar imágenes de este dígito, y su tiempo de entrenamiento se reducirá considerablemente.\n",
        "\n",
        "### Descargar conjunto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Fijar la semilla para obtener reproducibilidad y crear variable device\n",
        "seed = 42\n",
        "torch.manual_seed(seed)  # Fijar semilla de PyTorch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Definimos una transformación que convierte las imágenes a tensores.\n",
        "# La transformación ToTensor() convierte una imagen PIL en un tensor de PyTorch.\n",
        "# El compose permite concatenar múltiples transformaciones, en este caso solo aplicamos una.\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Descargamos el dataset indicando donde almacenarlo, la partición y las transformaciones\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "# Para simplificar el problema, solo nos quedaremos con imágenes de la clase 6\n",
        "selected_images = [idx for idx, l in enumerate(mnist_train) if l[1]==6]\n",
        "mnist_train = torch.utils.data.Subset(mnist_train, selected_images)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Tras descargar, ya tentemos un objeto Dataset, por lo que necesitamos un DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.6.2 - Arquitectura del modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Red Generadora\n",
        "Esta red se encargará de transformar un vector de ruido Gaussiano en $\\mathbb{R}^{100}$ en una imagen de $1 \\times 28 \\times 28$. Para ello se aplicarán de forma consecutiva una serie de convoluciones transpuestas (deconvoluciones) que generarán el volumen deseado.\n",
        "\n",
        "> **NOTA:** Hay que tener en cuenta que la red generadora ha de crear imágenes en el mismo rango de valores que las imágenes reales. De no hacerlo, el discriminador tendría muy facil su tarea de detectar imágenes verdaderas y falsas.\n",
        "En este caso, las imágenes del conjunto MNIST ya vienen normalizadas en el rango $[0, 1]$, por tanto pondremos una función de activación *sigmoide* a la salida de nuestra red para obtener el mismo resultado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "   \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(100, 32*7*7)\n",
        "        self.trans_conv1 = nn.ConvTranspose2d(32, 16, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
        "        self.trans_conv2 = nn.ConvTranspose2d(16, 8, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.trans_conv3 = nn.ConvTranspose2d(8, 4, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.trans_conv4 = nn.ConvTranspose2d(4, 1, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 32, 7, 7)\n",
        "        x = F.relu(self.trans_conv1(x))\n",
        "        x = F.relu(self.trans_conv2(x))\n",
        "        x = F.relu(self.trans_conv3(x))\n",
        "        x = self.trans_conv4(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        \n",
        "        return x        \n",
        "\n",
        "G = Generator().to(device)\n",
        "summary(G, (1, 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Red Discriminadora\n",
        "La segunda red es la encargada de clasificar, dada una imagen de $1 \\times 28 \\times 28$, en verdadera o generada mediante clasificación binaria. Para ello aplicaremos de forma consecutiva una serie de convoluciones que irán transformando un volumen de activaciones en otro hasta llegar a una única neurona de salida.\n",
        "\n",
        "> **NOTA:** En este caso no se pone función de activación en la salida (sigmoide) puesto que se va a utilizar la loss *BCEWithLogitsLoss*, la cual incorpora esta función entre sus cálculos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv0 = nn.Conv2d(1, 16, kernel_size = 3, stride = 2, padding = 1)\n",
        "        self.conv0_drop = nn.Dropout2d(0.25)\n",
        "        self.conv1 = nn.Conv2d(16, 8, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv1_drop = nn.Dropout2d(0.25)\n",
        "        self.conv2 = nn.Conv2d(8, 4, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv2_drop = nn.Dropout2d(0.25)\n",
        "        self.adavg = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc = nn.Linear(4, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.conv0(x), 0.2)\n",
        "        x = self.conv0_drop(x)\n",
        "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
        "        x = self.conv1_drop(x)\n",
        "        x = F.leaky_relu(self.conv2(x), 0.2)\n",
        "        x = self.conv2_drop(x)\n",
        "        x = self.adavg(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "D = Discriminator().to(device)\n",
        "summary(D, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación tendremos que crear ambas redes y definir la loss que queremos para nuestro problema. Se han creado 4 funciones auxiliares que nos servirán a la hora de realizar el entrenamiento de la DCGAN:\n",
        "\n",
        "1. ``discriminator_real_loss()``: Recibe las predicciones del discriminador $\\mathbf{\\hat{y}}$ para las imágenes reales y calcula la loss respecto de un vector de unos (la $\\mathbf{y}$).\n",
        "2. ``discriminator_fake_loss()``: Recibe las predicciones del discriminador $\\mathbf{\\hat{y}}$ para las imágenes generadas y calcula la loss respecto de un vector de ceros (la $\\mathbf{y}$).\n",
        "3. ``discriminator_loss()``: Acumula las losses anteriores, lo que resulta en la loss del discriminador.\n",
        "4. ``generator_loss()``: Recibe las predicciones del discriminador ante las entradas del generador (generadas) y calcula la loss respecto de un vector de unos (la $\\mathbf{y}$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def discriminator_real_loss(real_out):\n",
        "    real_label = torch.ones(real_out.size()[0], 1).to(device)\n",
        "    real_loss = Loss(real_out.squeeze(), real_label.squeeze())\n",
        "    return real_loss\n",
        "\n",
        "def discriminator_fake_loss(fake_out):\n",
        "    fake_label = torch.zeros(fake_out.size()[0], 1).to(device)\n",
        "    fake_loss = Loss(fake_out.squeeze(), fake_label.squeeze())\n",
        "    return fake_loss\n",
        "\n",
        "def discriminator_loss(real_out, fake_out):\n",
        "    real_loss = discriminator_real_loss(real_out)\n",
        "    fake_loss = discriminator_fake_loss(fake_out)\n",
        "    total_loss = (real_loss + fake_loss)\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(gen_disc_out):\n",
        "    label = torch.ones(gen_disc_out.size()[0], 1).to(device)\n",
        "    gen_loss = Loss(gen_disc_out.squeeze(), label.squeeze())\n",
        "    return gen_loss\n",
        "\n",
        "# Volvemos a crear los modelos para que, si cambiamos el LR, se haga reset.\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "# Para estabilizar el entrenamiento de una GAN, se recomienda utilizar beta1 = 0.5 en el Adam\n",
        "disc_opt = optim.Adam(D.parameters(), lr = 0.0005, betas = (0.5, 0.999))\n",
        "gen_opt =  optim.Adam(G.parameters(), lr = 0.0005, betas = (0.5, 0.999))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente ya solo quedaría la parte más compleja, entrenar el modelo. Para cada batch tendremos que:\n",
        "\n",
        "1. *Entrenar el discriminador:*\n",
        "    * Se obtienen las predicciones del discriminador para los ejemplos del bath (los reales).\n",
        "    * Se generan tantos vectores de ruido en $\\mathbb{R}^{100}$ como ejemplos tenga el batch y se pasan por el generador **(congelando previamente sus pesos)**.\n",
        "    * Se obtiene la loss del discriminador a partir de las predicciones del mismo ante los ejemplos reales y los falsos.\n",
        "    * Optimizamos el discriminador.\n",
        "\n",
        "2. *Entrenar el generador:*\n",
        "    * Se generan nuevos vectores de ruido y se pasan por el generador. En este caso generamos $2*batch\\_size$ para que el generador y el discriminador se optimicen con el mismo número de ejemplos.\n",
        "    * Se obtiene la predicción del discriminador ante los ejemplos anteriores y su loss correspondiente forzando al discriminador a predecir 1.\n",
        "    * Optimizamos el generador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def random_noise_generator(batch_size, dim):\n",
        "    # Generar ruido normalizado entre -1 y 1\n",
        "    return torch.rand(batch_size, dim)*2 - 1\n",
        "\n",
        "def train(D, G, disc_opt, gen_opt, train_dl, batch_size, epochs = 25, gen_input_size = 100):\n",
        "    \n",
        "    # Listas para almacenar las losses\n",
        "    disc_losses = []\n",
        "    gen_losses = []\n",
        "    \n",
        "    # Para mostrar la evolución del generador cada época, generamos unos ejemplos aleatorios\n",
        "    sample_size = 8\n",
        "    fixed_samples = random_noise_generator(sample_size, gen_input_size)\n",
        "    fixed_samples = fixed_samples.to(device)\n",
        "    \n",
        "    for epoch in range(epochs + 1):\n",
        "        #Ponemos en modo Train ambos modelos\n",
        "        D.train()\n",
        "        G.train()\n",
        "        \n",
        "        disc_loss_total = 0\n",
        "        gen_loss_total = 0\n",
        "        gen_out = 0\n",
        "        \n",
        "        for train_x, _ in tqdm(train_dl):\n",
        "            \n",
        "            # -----------------------------------------------------------------------------\n",
        "            # Entrenamiento del discriminador\n",
        "            # -----------------------------------------------------------------------------\n",
        "            \n",
        "            # Reiniciar gradientes\n",
        "            disc_opt.zero_grad() \n",
        "            \n",
        "            # Generamos predicciones a partir de las imágenes reales\n",
        "            train_x = train_x.to(device)\n",
        "            real_out = D(train_x.float())     \n",
        "            \n",
        "            # Generamos tantos vectores de ruido como elementos hay en el batch (para alimentar el generador)\n",
        "            disc_gen_in = random_noise_generator(batch_size, gen_input_size)\n",
        "            disc_gen_in = disc_gen_in.to(device)\n",
        "            \n",
        "            # Obtenemos las predicciones del generador ante el ruido anterior.\n",
        "            # Para congelar sus pesos, hay que hacer detach()\n",
        "            disc_gen_out = G(disc_gen_in.float()).detach()\n",
        "            fake_out = D(disc_gen_out.float())\n",
        "            \n",
        "            # Obtenemos la loss del discriminador, obtenemos gradientes y actualizamos pesos\n",
        "            # Pretendemos que para las salidas reales prediga 1 y para las falsas 0\n",
        "            disc_loss = discriminator_loss(real_out, fake_out)\n",
        "            disc_loss_total += disc_loss.item()\n",
        "            disc_loss.backward()\n",
        "            disc_opt.step()  \n",
        "            \n",
        "            # -----------------------------------------------------------------------------\n",
        "            # Entrenamiento del generador\n",
        "            # -----------------------------------------------------------------------------\n",
        "\n",
        "            # Reiniciar gradientes\n",
        "            gen_opt.zero_grad()\n",
        "            \n",
        "            # Obtenemos las predicciones del generador para nuevo ruido.\n",
        "            gen_gen_in = random_noise_generator(batch_size*2, gen_input_size)\n",
        "            gen_gen_in = gen_gen_in.to(device)\n",
        "            gen_out = G(gen_gen_in.float())     \n",
        "            gen_disc_out = D(gen_out.float())       \n",
        "            \n",
        "            # Obtenemos la loss del discriminador, obtenemos gradientes y actualizamos pesos\n",
        "            # Ahora pretendemos que para las salidas generadas prediga 1\n",
        "            gen_loss = generator_loss(gen_disc_out) \n",
        "            gen_loss_total += gen_loss.item()\n",
        "            gen_loss.backward()\n",
        "            gen_opt.step()\n",
        "        \n",
        "        disc_losses.append(disc_loss_total)\n",
        "        gen_losses.append(gen_loss_total)\n",
        "        \n",
        "        #Plotting samples\n",
        "        G.eval()                    #Going into eval mode to get sample images         \n",
        "        samples = G(fixed_samples.float())\n",
        "        G.train()                   #Going back into train mode\n",
        "        \n",
        "        # Borrar la consola\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        fig, axes = plt.subplots(figsize=(7,3), nrows=2, ncols=4, sharey=True, sharex=True)\n",
        "        for ax, img in zip(axes.flatten(), samples):\n",
        "            img = img.cpu().detach()\n",
        "            ax.xaxis.set_visible(False)\n",
        "            ax.yaxis.set_visible(False)\n",
        "            im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
        "        plt.show()\n",
        "        \n",
        "        #Printing losses every epoch\n",
        "        print(\"Epoch \", epoch, \": Discriminator Loss = \", disc_loss_total/len(train_dl), \", Generator Loss = \", gen_loss_total/len(train_dl))    \n",
        "    \n",
        "    return disc_losses, gen_losses\n",
        "\n",
        "disc_losses, gen_losses = train(D, G, disc_opt, gen_opt, train_loader, epochs=100, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.6.3. - Ejercicios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **EJERCICIO:** Re-entrena y modifica la DCGAN anterior para que genere imágenes de los dígitos 0 y 1. Realiza un máximo de 50 épocas con un $ learning\\_rate=0.001$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **EJERCICIO:** Crea y entrena una versión condicional de la red anterior que permita decidir que dígito generar. Para ello tendrás que incorporar una entrada adicional en el generador y discriminador indicando el tipo de dígito. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
