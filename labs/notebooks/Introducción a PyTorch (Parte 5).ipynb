{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a PyTorch (Parte 5)\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/pglez82/DeepLearningWeb/blob/master/labs/notebooks/Introducci%C3%B3n%20a%20PyTorch%20(Parte%205).ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook vamos a utilizar los conocimientos aprendidos en los notebooks anteriores para realizar un entrenamiento más avanzando. En particular aprenderemos lo siguiente:\n",
    "- Carga de un dataset.\n",
    "- Particionado de los datos.\n",
    "- Creación de los DataLoaders.\n",
    "- Bucle de entrenamiento, validación y early stopping.\n",
    "- Salvar el modelo y checkpoints intermedios. Carga de modelos.\n",
    "- Inferencia.\n",
    "\n",
    "Trabajaremos en este caso con el conjunto FashionMNIST, un conjunto con **10 clases**, 60.000 ejemplos de entrenamiento y 10.000 ejemplos para test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de los datos\n",
    "Procederemos igual que en la práctica anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(root=\"data\",train=True,download=True,transform=ToTensor())\n",
    "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Utilizando dispositivo: %s\" % device)\n",
    "\n",
    "print(\"Datos de entrenamiento:\")\n",
    "print(training_data, end='\\n\\n')\n",
    "print(\"Datos de test:\")\n",
    "print(test_data, end='\\n\\n')\n",
    "\n",
    "# Separación de un conjunto de validación\n",
    "training_data, validation_data = random_split(training_data,(50000,10000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de los datos\n",
    "\n",
    "Visualizamos algunos datos para ver como son las imágenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"Camiseta\",\n",
    "    1: \"Pantalón\",\n",
    "    2: \"Jersey\",\n",
    "    3: \"Vestido\",\n",
    "    4: \"Abrigo\",\n",
    "    5: \"Sandalia\",\n",
    "    6: \"Camisa\",\n",
    "    7: \"Zapatilla\",\n",
    "    8: \"Bolso\",\n",
    "    9: \"Bota\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(5, 5))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de los DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_dataloader = DataLoader(validation_data, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de la red\n",
    "En este caso utilizaremos de nuevo una red totalmente conectada, aunque sería más adecuado utilizar una red convolucional para mejorar el rendimiento del sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dropout=0.2, linear_sizes = (50, 50, 10)):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.Sequential()\n",
    "        previous_size = 28*28 # la entrada tienen que coincidir con el número de pixeles en la imagen\n",
    "        for i, linear_size in enumerate(linear_sizes):\n",
    "            self.layers.append(nn.Linear(previous_size, linear_size))\n",
    "            if i != len(linear_sizes):\n",
    "                # Añadir dropout y función de activación salvo en la última capa de salida\n",
    "                self.layers.append(nn.ReLU())\n",
    "                self.layers.append(nn.Dropout(dropout))\n",
    "            previous_size = linear_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de los bucles de validación y entrenamiento\n",
    "Aquí vamos a crear los bucles de entrenamiento de la red. En primer lugar creamos el bucle de validación, que se encarga de calcular la función de pérdida en el conjunto de validación. Ten en cuenta que en este caso no necesitamos actualizar los gradientes de la red, por tanto utilizamos `torch.no_grad()` y ponemos la red en modo evaluación con el método `eval()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loss_module, val_dataloader):\n",
    "    val_loss=0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data_inputs, data_labels in val_dataloader:\n",
    "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "            logits = model(data_inputs)\n",
    "            val_loss += loss_module(logits, data_labels)\n",
    "        return val_loss/ len(val_dataloader)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el bucle de entrenamiento, después de acabar cada época, calculamos el error de validación y lo imprimimos. Este error también se usa para realizar la **parada temprana**, cuando el error de validación deje de decrecer. También aprovechamos para salvar el mejor modelo hasta el momento. Para ello utilizamos la instrucción: `torch.save(model.state_dict(), 'best_model.pth')`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_model(model, optimizer, train_dataloader, val_dataloader, loss_module, patience=3, max_epochs=50):\n",
    "    \n",
    "    min_loss = float('inf')\n",
    "    no_improvement = 0\n",
    "\n",
    "    # Bucle de entrenamiento\n",
    "    pbar = tqdm(range(max_epochs))\n",
    "    for epoch in pbar:\n",
    "        # Poner el modelo en modo entrenamiento\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for data_inputs, data_labels in train_dataloader:\n",
    "            #Hacer una pasada hacia delante\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels = data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            # La salida es [Batch size, 1], queremos [Batch size]\n",
    "            preds = preds.squeeze(dim=1)  \n",
    "            #Calcular el valor de la función de pérdida para este mini-batch\n",
    "            loss = loss_module(preds, data_labels)\n",
    "            #Acumular el error (solo para luego mostrarlo)\n",
    "            epoch_loss += loss.item()\n",
    "            #Reiniciar los gradientes\n",
    "            optimizer.zero_grad()\n",
    "            #Pasada hacia atrás\n",
    "            loss.backward()\n",
    "            #Actualizar los parámetros\n",
    "            optimizer.step()\n",
    "        val_loss = validation(model, loss_module, val_dataloader)\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            no_improvement=0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "\n",
    "        pbar.set_description(\"Training Loss %0.2f. Validation Loss %0.2f. Patience: %d/%d\" % (epoch_loss/len(train_dataloader), val_loss, no_improvement, patience))\n",
    "        if no_improvement>=patience:\n",
    "            print(\"No hay mejora por %d épocas. Parada Temprana!!\" % patience)\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando la red\n",
    "Una vez que tenemos todo preparado estamos en situación de entrenar la red. Para ello inicializamos el modelo y lanzamos el entrenamiento. Hay que tener en cuenta que el mejor modelo quedará salvado en el archivo `best_model.pth`, que luego podremos utilizar para inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(dropout=0.2, linear_sizes=(50,10))\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "train_model(model, optimizer, train_dataloader, val_dataloader, loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencia\n",
    "Una vez que tenemos entrenado el modelo es momento de evaluar el conjunto de test con él y analizar las métricas que estemos interesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el mejor modelo\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data_inputs, data_labels in test_dataloader:\n",
    "        data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "        logits = model(data_inputs)\n",
    "        _, predicted_classes = torch.max(logits, 1)  # Get the predicted classes\n",
    "        correct_predictions += (predicted_classes == data_labels).sum().item()\n",
    "        total_predictions += data_labels.size(0)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(\"Accuracy: {:.2%}\".format(accuracy))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "1. Modifica el código para que tanto en el entrenamiento como en validación se calcule (y se imprima en la barra de progreso) también el acierto del modelo y no solo el cross entropy.\n",
    "2. Modifica los hiperparámetros del entrenamiento. ¿Hasta donde eres capaz de llevar el acierto en test?\n",
    "3. Modifica el número de capas lineales y su tamaño. ¿Puedes mejorar el acierto de la red?\n",
    "4. Prueba a cargar el conjunto de entrenamiento completo en la GPU para no tener que mover cada batch. ¿Notas alguna diferencia en velocidad?\n",
    "5. Modifica el código para salvar en cada época la loss de entrenamiento y de validación y al final del entrenamiento, pinta una gráfica para ver como han progresado ambas métricas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
